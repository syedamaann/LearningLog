{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "from gensim.downloader import load\n",
    "\n",
    "# Load pre-trained GloVe embeddings\n",
    "glove_model = load(\"glove-wiki-gigaword-50\")\n",
    "\n",
    "# Sample texts\n",
    "texts = [\"The cat sits on the mat.\", \"A cat is on the mat.\", \"Dogs are running in the park.\", \"Children are playing in the park.\"]\n",
    "\n",
    "# Tokenize texts\n",
    "tokenized_texts = [text.lower().split() for text in texts]\n",
    "\n",
    "# Function to get GloVe embeddings for a token\n",
    "def get_glove_embedding(token):\n",
    "    try:\n",
    "        return glove_model[token]\n",
    "    except KeyError:\n",
    "        return np.zeros(50)  # return zero vector if token not in GloVe\n",
    "\n",
    "# Get embeddings for all tokens in texts\n",
    "all_tokens = set([token for text in tokenized_texts for token in text])\n",
    "glove_embeddings = {token: get_glove_embedding(token) for token in all_tokens}\n",
    "glove_tokens = list(glove_embeddings.keys())\n",
    "glove_vectors = np.array(list(glove_embeddings.values()))\n",
    "\n",
    "# Compute sentence embeddings as the average of token embeddings\n",
    "sentence_vectors = np.array([\n",
    "    np.mean([get_glove_embedding(token) for token in text], axis=0)\n",
    "    for text in tokenized_texts\n",
    "])\n",
    "\n",
    "# Combine all embeddings for visualization\n",
    "all_vectors = np.concatenate((glove_vectors, sentence_vectors), axis=0)\n",
    "all_tokens = glove_tokens + texts\n",
    "\n",
    "# Apply PCA\n",
    "pca = PCA(n_components=2)\n",
    "reduced_vectors = pca.fit_transform(all_vectors)\n",
    "\n",
    "# Visualization\n",
    "plt.figure(figsize=(12, 8))\n",
    "for i, token in enumerate(all_tokens):\n",
    "    plt.scatter(reduced_vectors[i, 0], reduced_vectors[i, 1])\n",
    "    plt.text(reduced_vectors[i, 0] + 0.01, reduced_vectors[i, 1] + 0.01, token, fontsize=9)\n",
    "\n",
    "plt.title('Embeddings Visualization using PCA')\n",
    "plt.xlabel('PCA Component 1')\n",
    "plt.ylabel('PCA Component 2')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "05_embeddingmodels",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
